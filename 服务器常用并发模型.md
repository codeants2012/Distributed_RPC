## 服务器常用并发模型

------

### 1.单线程同步模型

> 单线程同步模型是最简单的服务器模型，每次只能处理一个客户端的连接，其他连接必须要等到前面的

连接关闭后才能得到服务器的处理，否则发过来的请求会悬挂住，没有任何响应；服务端是串行地处理客

户端的连接的

> 一个客户端必须要等到另外一个客户端运行结束后才可以运行，这也太慢了吧

### 2.多线程同步模型

> 服务器可以并行地处理多个客户端的连接，没来一个连接就开启一个新的线程单独进行处理，每个线程

都是同步读写客户端的连接的

### 3.多进程同步模型

> Java使用者很少能够体会多进程的魅力，他们都是使用多线程。但是在Python中并不常见，因为Python

的GIL只能使单个进程占满一个CPU核心，多线程不能利用多核的优势，所以Python服务器可以使用多进程

模型

### 4.PreForking同步模型

> 进程在操作系统中是非常耗资源的，所以要对服务器开辟的进程数量进行限制，避免系统的负载过重，

这就是多进程PreForking模型。

> 这种模型预先产生多个子进程，共同对服务器套接字竞争资源，但是最终只能有一个进程获取到。

如果并行的连接数超过了prefork的数量，那么后来的客户端请求将会阻塞。但是这样也可以通过子进程

的单线程同步模型改成多进程同步模型的方式解决

### 5.单进程异步模型

> 上述的服务器模型都是同步的，而现代的服务器一般都是异步的，效率是比较高的，它是一种非阻塞的

服务器模型，实现了对进程和线程的解放，再加上事件轮询机制的配合使得它的性能比同步高出了许多

> 像Nignx、Nodejs、Redis都是基于异步模型构建出来的，性能非常高

### 6.PreForking 异步模型

> 单进程的IO并发能力有限，虽然使用了事件轮询和异步读写功能，但是还不能应对高并发的需求，所以

需要使用多进程，这样也可以对我们的CPU最大限度的利用

> 开源的Tornado服务器和Nignx就是采用了多进程PreForking模型达到了超高并发的处理能力



